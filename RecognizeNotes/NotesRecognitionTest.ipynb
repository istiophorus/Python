{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image as tfimg\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomTranslation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "notesList = [\n",
    "(\"100a\", \"100_awers.jpg\"),\n",
    "(\"100r\", \"100_rewers.jpg\"),\n",
    "(\"10a\", \"10_awers.jpg\"),\n",
    "(\"10r\", \"10_rewers.jpg\"),\n",
    "(\"200a\", \"200_awers.jpg\"),\n",
    "(\"200r\", \"200_rewers.jpg\"),\n",
    "(\"20a\", \"20_awers.jpg\"),\n",
    "(\"20r\", \"20_rewers.jpg\"),\n",
    "(\"50a\", \"50_awers.jpg\"),\n",
    "(\"50r\", \"50_rewers.jpg\"),\n",
    "(\"100a\", \"NBP_500_strona_przednia2.jpg\"),\n",
    "(\"100r\", \"tyl_100.jpg\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(original)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "    flipped = tf.image.flip_left_right(image)\n",
    "    visualize(image, flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_augmentation_model():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        RandomZoom(height_factor=0.2, width_factor=0.2, fill_mode=\"constant\"),\n",
    "        RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"constant\"),\n",
    "        RandomRotation(0.2)\n",
    "    ])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notes_images(directory, notesList):\n",
    "    result = []\n",
    "    for pair in notesList:\n",
    "        label = pair[0]\n",
    "        fullPath = directory + '/' + pair[1]\n",
    "        rawImage = tfimg.load_img(fullPath, target_size=(224, 224))\n",
    "        imgArr = tfimg.img_to_array(rawImage)\n",
    "        expanded = np.expand_dims(imgArr, axis=0)\n",
    "        x = preprocess_input(expanded)\n",
    "        result.append((label, fullPath, rawImage, expanded, x))    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_data(notesImages, data_augmentation):\n",
    "    augmentedData = []\n",
    "    for imageTuple in notesImages:\n",
    "        label, fullPath, rawImage, expanded, preprocessed = imageTuple\n",
    "        augmentedData.append(imageTuple)\n",
    "        for i in range(50):\n",
    "            augmented_image = data_augmentation(expanded)\n",
    "            preprocessed_augmented = preprocess_input(augmented_image)\n",
    "            augmentedData.append((label, \"\", None, augmented_image, preprocessed_augmented))\n",
    "    return augmentedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(augmentedData, model):\n",
    "    extractedFeatures = []\n",
    "\n",
    "    for ad in augmentedData:\n",
    "        preprocessedImage = ad[4]\n",
    "        label = ad[0]\n",
    "        features = model.predict(preprocessedImage)\n",
    "        extractedFeatures.append((label, features))\n",
    "        \n",
    "    return extractedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "notesImages = load_notes_images(\"d:/Dane/banknoty_PLN\", notesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = create_data_augmentation_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentedData = create_augmented_data(notesImages, data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(augmentedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedFeatures = extract_features(augmentedData, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_extracted_features_to_np_array(extractedFeatures):\n",
    "    acc = None\n",
    "    labels = []\n",
    "\n",
    "    for ef in extractedFeatures:\n",
    "        aux = ef[1].flatten().reshape((1, 25088))\n",
    "        label = ef[0]\n",
    "        if acc is None:\n",
    "            acc = aux\n",
    "        else:\n",
    "            acc = np.append(acc, aux, axis=0)\n",
    "        labels.append(label)\n",
    "        \n",
    "    labelsArr = np.array(labels)\n",
    "            \n",
    "    return (acc, labelsArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features = convert_extracted_features_to_np_array(extractedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_evaluate_model(merged_features, componentsCount):\n",
    "    X = merged_features[0]\n",
    "    y = merged_features[1]    \n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "    \n",
    "    pca = PCA(n_components=componentsCount)\n",
    "    X_train_minmax_pcs = pca.fit_transform(X_train_minmax)\n",
    "    \n",
    "    X_test_minmax = min_max_scaler.transform(X_test)\n",
    "    X_test_minmax_pca = pca.transform(X_test_minmax)\n",
    "    \n",
    "    X_train_preprocessed = X_train_minmax_pcs\n",
    "    X_test_preprocessed = X_test_minmax_pca\n",
    "    \n",
    "    nextModel = GridSearchCV(estimator=SVC(), param_grid={'C': [0.1, 1, 10, 100], 'kernel': ('linear', 'rbf')}) #SVC(gamma='auto')\n",
    "    \n",
    "    readySvcModel = nextModel.fit(X_train_preprocessed, y_train)\n",
    "    y_predict = nextModel.predict(X_test_preprocessed)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702970297029703"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_evaluate_model(merged_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "#plt.imshow(image[0])\n",
    "\n",
    "#for i in range(10):\n",
    "#    augmented_image = augmentedData[i][3]\n",
    "#    print(augmented_image.shape)\n",
    "#    ax = plt.subplot(3, 3, i + 1)\n",
    "#   plt.imshow(augmented_image[0])\n",
    "#   plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
